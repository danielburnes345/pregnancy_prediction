{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e84b16-ca8f-41fc-b4b9-21cc7348a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10fc7b66-a297-4c17-a26b-28b0b8065404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff3aa0f-3054-4308-bc4e-b7d84d713966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample = [([[3, 'protected_sex'], [8, 'emotion_neutral'], [10, 'withdrawl_sex'], [12, 'withdrawl_sex'], [13, 'emotion_sad'], [14, 'emotion_neutral'], [14, 'protected_sex'], [17, 'emotion_sad'], [19, 'emotion_happy'], [21, 'emotion_sad'], [23, 'emotion_sad']], 0)]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# parameters\n",
    "cycleLength = 24  # cycleLength is D -- we consider features in first D days\n",
    "sexRisks = {\n",
    "    \"unprotected_sex\": 0.5,\n",
    "    \"protected_sex\": 0.2,\n",
    "    \"withdrawl_sex\": 0.3,\n",
    "}\n",
    "\n",
    "emotionImpacts = {\n",
    "    \"emotion_happy\": 1.2,\n",
    "    \"emotion_neutral\": 1.0,\n",
    "    \"emotion_sad\": 0.8,\n",
    "}\n",
    "\n",
    "# Convert dict_keys objects to lists and concatenate them\n",
    "symptomNames = list(sexRisks.keys()) + list(emotionImpacts.keys())\n",
    "\n",
    "# Create a dictionary to map symptom names to indices\n",
    "symptomIndices = {name: idx for idx, name in enumerate(symptomNames)}\n",
    "\n",
    "\n",
    "# TODO: use some better way to simulate this instead of fixed fertilities\n",
    "def genFertilities(cycleLength):\n",
    "    fertilities = np.array([\n",
    "        1, 1, 1, 1, 1,\n",
    "        1, 2, 3, 10, 12,\n",
    "        13, 11, 10, 8, 10,\n",
    "        9, 5, 3, 2, 1,\n",
    "        1, 1, 1, 1, 1,\n",
    "        2, 1, 1, 2, 1,\n",
    "        1, 1, 0, 0, 0,\n",
    "    ], dtype=float)\n",
    "    maxFertility = 0.8\n",
    "    assert cycleLength <= fertilities.shape[0]\n",
    "    return fertilities[:cycleLength] / np.max(fertilities) * maxFertility\n",
    "\n",
    "\n",
    "def flipWithProb(prob):\n",
    "    return np.random.random() <= prob\n",
    "\n",
    "\n",
    "# Basic assumptions for single cycle data generation\n",
    "#   - fertility: agrees with fertility window. Some factors like age, emotion\n",
    "#     can affect fertility on the cycle or on a specific day.\n",
    "#   - sex: different sex types have different risks, and it should be\n",
    "#     considered together with fertility.\n",
    "# Return:\n",
    "#   (features, label), where features = [(day, symptom)...]\n",
    "def genSingleCycleData():\n",
    "    features = []\n",
    "    sexProb = 0.15  # prob for sex symptom\n",
    "    emotionProb = 0.3  # prob for emotion symptom\n",
    "    epsilon = 0.05  # random noise scale\n",
    "    probs = []  # probs for each sex\n",
    "    fertility = genFertilities(cycleLength)\n",
    "    for d in range(cycleLength):\n",
    "        fertilityFactor = 1.\n",
    "        if flipWithProb(emotionProb):  # emotion\n",
    "            emotionIdx = np.random.randint(0, 3)\n",
    "            emotionName = list(emotionImpacts.keys())[emotionIdx]\n",
    "            fertilityFactor *= emotionImpacts[emotionName]\n",
    "            features.append([d, emotionName])\n",
    "        if flipWithProb(sexProb):  # have sex\n",
    "            sexIdx = np.random.randint(0, 3)\n",
    "            sexName = symptomNames[sexIdx]\n",
    "            f = fertility[d] * fertilityFactor\n",
    "            probs.append(f * sexRisks[sexName])\n",
    "            features.append([d, sexName])\n",
    "    finalProb = 1 - np.prod(1 - np.array(probs)) + np.random.randn() * epsilon\n",
    "    finalProb = max(0, finalProb)\n",
    "    # print(\"# finalProb: {}\".format(finalProb))\n",
    "    label = 1 if finalProb > 0.5 else 0\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def genCycleData(num=0):\n",
    "    data = [genSingleCycleData() for i in range(num)]\n",
    "    return data\n",
    "\n",
    "def convertToNdarray(data):\n",
    "    numSymptom = len(symptomNames)\n",
    "    dataNpy = np.zeros((len(data), 1 + numSymptom * cycleLength))\n",
    "    for i, entry in enumerate(data):\n",
    "        dataNpy[i][0] = entry[1]\n",
    "        for symptom in entry[0]:\n",
    "            day = symptom[0]\n",
    "            symptomName = symptom[1]\n",
    "            symptomIndex = symptomIndices[symptomName]\n",
    "            dataNpy[i][1 + numSymptom * day + symptomIndex] = 1\n",
    "    return dataNpy\n",
    "\n",
    "def splitAndSave(dataNpy, trainPercent, devPercent, testPercent, dataDir):\n",
    "    n = dataNpy.shape[0]\n",
    "\n",
    "    np.random.shuffle(dataNpy)\n",
    "\n",
    "    trainCount = int(n * trainPercent)\n",
    "    devCount = int(n * devPercent)\n",
    "\n",
    "    dataSplits = {\n",
    "        \"train\": dataNpy[:trainCount, :],\n",
    "        \"dev\": dataNpy[trainCount:trainCount+devCount, :],\n",
    "        \"test\": dataNpy[trainCount+devCount:, :]\n",
    "    }\n",
    "\n",
    "    for k, v in dataSplits.items():\n",
    "        splitDir = os.path.join(dataDir, k)\n",
    "        os.mkdir(splitDir)\n",
    "        splitFile = os.path.join(splitDir, k+\".npy\")\n",
    "        np.save(splitFile, v)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = genCycleData(1)\n",
    "    print(\"sample = {}\".format(data))\n",
    "    print(len(data[0][0]))\n",
    "    data = genCycleData(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2457c7b1-0f8d-445d-8ac0-dcdb23edf17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = set()\n",
    "for sample, _ in data:\n",
    "    features = [feature for _, feature in sample]\n",
    "    all_features.update(features)\n",
    "\n",
    "feature_to_index = {feature: idx+1 for idx, feature in enumerate(sorted(all_features))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566b32f9-939e-432e-b6f9-2720122a4e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emotion_happy': 1,\n",
       " 'emotion_neutral': 2,\n",
       " 'emotion_sad': 3,\n",
       " 'protected_sex': 4,\n",
       " 'unprotected_sex': 5,\n",
       " 'withdrawl_sex': 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fbb340-0b47-40eb-9a0e-d3ddfbb1b75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[0, 'withdrawl_sex'],\n",
       "   [1, 'emotion_sad'],\n",
       "   [2, 'emotion_sad'],\n",
       "   [3, 'emotion_happy'],\n",
       "   [6, 'emotion_neutral'],\n",
       "   [8, 'unprotected_sex'],\n",
       "   [14, 'withdrawl_sex'],\n",
       "   [16, 'emotion_sad'],\n",
       "   [19, 'emotion_happy'],\n",
       "   [20, 'emotion_neutral']],\n",
       "  0),\n",
       " ([[0, 'unprotected_sex'],\n",
       "   [1, 'withdrawl_sex'],\n",
       "   [3, 'unprotected_sex'],\n",
       "   [6, 'emotion_happy'],\n",
       "   [10, 'protected_sex'],\n",
       "   [14, 'emotion_neutral'],\n",
       "   [15, 'emotion_neutral'],\n",
       "   [20, 'emotion_sad'],\n",
       "   [21, 'withdrawl_sex'],\n",
       "   [22, 'protected_sex'],\n",
       "   [23, 'emotion_happy']],\n",
       "  0),\n",
       " ([[1, 'emotion_neutral'],\n",
       "   [2, 'emotion_happy'],\n",
       "   [3, 'unprotected_sex'],\n",
       "   [5, 'withdrawl_sex'],\n",
       "   [11, 'emotion_sad'],\n",
       "   [11, 'unprotected_sex'],\n",
       "   [12, 'emotion_sad'],\n",
       "   [13, 'emotion_happy'],\n",
       "   [14, 'emotion_sad'],\n",
       "   [16, 'emotion_happy'],\n",
       "   [17, 'emotion_neutral'],\n",
       "   [17, 'withdrawl_sex'],\n",
       "   [20, 'unprotected_sex'],\n",
       "   [22, 'emotion_sad']],\n",
       "  0),\n",
       " ([[2, 'emotion_happy'],\n",
       "   [4, 'emotion_neutral'],\n",
       "   [7, 'emotion_sad'],\n",
       "   [9, 'emotion_happy'],\n",
       "   [10, 'emotion_neutral'],\n",
       "   [11, 'emotion_sad'],\n",
       "   [12, 'emotion_neutral'],\n",
       "   [17, 'emotion_sad'],\n",
       "   [18, 'emotion_sad'],\n",
       "   [18, 'protected_sex'],\n",
       "   [21, 'emotion_happy']],\n",
       "  0),\n",
       " ([[0, 'emotion_happy'],\n",
       "   [3, 'protected_sex'],\n",
       "   [6, 'emotion_neutral'],\n",
       "   [6, 'protected_sex'],\n",
       "   [7, 'emotion_happy'],\n",
       "   [10, 'emotion_happy'],\n",
       "   [14, 'protected_sex'],\n",
       "   [15, 'emotion_neutral'],\n",
       "   [16, 'emotion_sad'],\n",
       "   [21, 'emotion_neutral']],\n",
       "  0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5716e32d-26bc-4618-b84e-857a1bd53415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "for sample, label in data:\n",
    "    sequence = [[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]]\n",
    "    for day,feature in sample:\n",
    "        if feature_to_index[feature] > 3:\n",
    "            sequence[day][1] = feature_to_index[feature]\n",
    "        else: \n",
    "            sequence[day][0] = feature_to_index[feature]\n",
    "    sequences.append(sequence)\n",
    "    labels.append(label)\n",
    "\n",
    "# Pad sequences\n",
    "max_length = 24\n",
    "X = np.array(sequences)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168bfce8-0f03-4155-a54d-b61fd8eba656",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ccb2b1c-b4a4-4a1b-b1ad-232abb6d56a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.4623 - val_accuracy: 0.9125 - val_loss: 0.2945\n",
      "Epoch 2/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.4352 - val_accuracy: 0.8625 - val_loss: 0.2849\n",
      "Epoch 3/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8780 - loss: 0.3523 - val_accuracy: 0.9125 - val_loss: 0.2798\n",
      "Epoch 4/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.3935 - val_accuracy: 0.9125 - val_loss: 0.2386\n",
      "Epoch 5/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.3195 - val_accuracy: 0.8875 - val_loss: 0.2541\n",
      "Epoch 6/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.2476 - val_accuracy: 0.9000 - val_loss: 0.2263\n",
      "Epoch 7/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.3078 - val_accuracy: 0.8625 - val_loss: 0.3155\n",
      "Epoch 8/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.3010 - val_accuracy: 0.9500 - val_loss: 0.2351\n",
      "Epoch 9/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.2793 - val_accuracy: 0.9375 - val_loss: 0.2246\n",
      "Epoch 10/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.3335 - val_accuracy: 0.8625 - val_loss: 0.2958\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Build RNN model\n",
    "model = Sequential([\n",
    "    SimpleRNN(50, input_shape=(X.shape[1], X.shape[2]), return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=2, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18f7c393-4ff9-44fd-8a34-d6cb6796d2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03194568]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [[1, 'protected_sex'],[2, 'protected_sex'],[3, 'withdrawl_sex'],[6, 'protected_sex'],[14,'withdrawl_sex'],[17,'withdrawl_sex'],[18,'emotion_sad']]\n",
    "values = [[0,0],\n",
    "        [0,4],\n",
    "        [0,4],\n",
    "        [0,6],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,4],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,5],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,6],\n",
    "        [3,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0],\n",
    "        [0,0]]\n",
    "values = np.array(values)\n",
    "values = values.reshape(1, len(values), 2)\n",
    "result = model.predict(values)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
